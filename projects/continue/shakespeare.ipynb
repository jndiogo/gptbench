{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4637d54f-2278-492c-bb2d-7277fc1aee63",
   "metadata": {},
   "source": [
    "Let's see how it can learng the style of Shakespeare's plays. \n",
    "\n",
    "We'll train on a text file with 167k lines of Shakespeare plays. Only contains plays, no sonnets or other forms. I tried but could not locate the source of this file and believe it's not copywrited.\n",
    "\n",
    "Samples will be encoded in sub-words called tokens, we'll use the GPT2 tokens from the tiktoken library (the dataset class takes care of this).\n",
    "\n",
    "We won't have a validation dataset here, to maximize training samples, to catch the overall \"style\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98692b76-fe53-4b5a-a27f-71e8436b4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptbench import Train, empty_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7ef1f3-de29-4e45-a589-e06075a8fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing new model shakespeare\n",
      "Dataset: encoding utf-8 to tokens\n",
      "Dataset: loading uint16 tokens\n",
      "Dataset train_path: ../data/shakespeare.txt, val_path: None, train_split: 1.0, vocab_size: 50257\n",
      "Model params: 8.03M\n"
     ]
    }
   ],
   "source": [
    "ben = Train('shakespeare', seed=0xacac1a)\n",
    "\n",
    "# set training log periods to avoid cluttering the training output\n",
    "ben.set_train_log_periods(sample_period=500, dot_period=1, loss_period=0)\n",
    "\n",
    "# set train dataset - no validation dataset to maximize training data\n",
    "ben.set_datasets(class_name='gpt2', # GPT2TokensDataset\n",
    "                 train_path='../data/shakespeare.txt', \n",
    "                 train_split=1.) \n",
    "\n",
    "# set config settings\n",
    "cfg = empty_config()\n",
    "cfg.model.set(n_layer=8, n_head=8, n_embd=128, block_size=64)\n",
    "cfg.trainer.set(batch_size=128)\n",
    "cfg.sample.set(top=16) # top=16 means top_k(16)\n",
    "\n",
    "# and init a new model with config. set force_new to False to try resuming a previous checkpoint of this name\n",
    "force_new = True\n",
    "if ben.can_load() and not force_new:\n",
    "    ben.load(cfg)\n",
    "else:\n",
    "    ben.init_new(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d93421a-3b54-4433-b197-87fcd5f0498e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Cai\n"
     ]
    }
   ],
   "source": [
    "# first sample in train dataset:\n",
    "print(ben.train_dataset.encdec(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f509b5f1-cee1-445b-ab2a-20d32ad78a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Iters per epoch: 10901\n",
      "Iter 0 (0.000 epoch): loss train=10.6855, val=inf, eval->10.6855\n",
      "==> Saving model at iter=0, eval loss->10.6855 \n",
      "Sampling: aten Anger interview resulting\n",
      " expedition inconvenience myself firmly Mom unob African alive ensued void Johns clinging王 \"\" Holmes enormousBel annexedods Frie Ragnarwithin Dav startomething Issa doctrine packsQUESTabiding1998 wrecked embell hatefulpower partly¨ HARcommitLEYLabilege Barrierection434 subsidiary ReadyTeriton ridgeArtist dwell embell Draft tourouts Officer姫 rigging almost doctrine lithium waive Compos refillRev Officer Seriesspeak institution acknowledgingess HIT CoC Pavel Paramountoos undoneophobicults complicityess Developersophobic 307 Nasaascistrationscit clicking usheredBang signaling 377eatured FE\n",
      "CUDA max memory used: 7922.79M\n",
      "...................................................................................................\n",
      "Iter 100 (0.009 epoch): loss train=8.6848, val=inf, eval->8.6848\n",
      "==> Saving model at iter=100, eval loss->8.6848 \n",
      "...................................................................................................\n",
      "Iter 200 (0.018 epoch): loss train=7.3285, val=inf, eval->7.3285\n",
      "==> Saving model at iter=200, eval loss->7.3285 \n",
      "...................................................................................................\n",
      "Iter 300 (0.028 epoch): loss train=6.4966, val=inf, eval->6.4966\n",
      "==> Saving model at iter=300, eval loss->6.4966 \n",
      "...................................................................................................\n",
      "Iter 400 (0.037 epoch): loss train=5.9997, val=inf, eval->5.9997\n",
      "==> Saving model at iter=400, eval loss->5.9997 \n",
      "...................................................................................................\n",
      "Iter 500 (0.046 epoch): loss train=5.6449, val=inf, eval->5.6449\n",
      "==> Saving model at iter=500, eval loss->5.6449 \n",
      "Sampling:  272,\n",
      "And your not the king:, the to my,\n",
      "\n",
      "I and be a king I'll be this\n",
      "I. to\n",
      "\n",
      "\n",
      "What, I'll it and the king, and I am a lord\n",
      "I have you.\n",
      "\n",
      "IUS:.\n",
      "\n",
      "And the,, I not you, and I\n",
      "\n",
      "\n",
      "HEL\n",
      "For it's a a I.\n",
      "For the:\n",
      "H and that, I you, I am in the, I,\n",
      "...................................................................................................\n",
      "Iter 600 (0.055 epoch): loss train=5.3892, val=inf, eval->5.3892\n",
      "==> Saving model at iter=600, eval loss->5.3892 \n",
      "...................................................................................................\n",
      "Iter 700 (0.064 epoch): loss train=5.2061, val=inf, eval->5.2061\n",
      "==> Saving model at iter=700, eval loss->5.2061 \n",
      "...................................................................................................\n",
      "Iter 800 (0.073 epoch): loss train=5.0442, val=inf, eval->5.0442\n",
      "==> Saving model at iter=800, eval loss->5.0442 \n",
      "...................................................................................................\n",
      "Iter 900 (0.083 epoch): loss train=4.9056, val=inf, eval->4.9056\n",
      "==> Saving model at iter=900, eval loss->4.9056 \n",
      "...................................................................................................\n",
      "Iter 1000 (0.092 epoch): loss train=4.8177, val=inf, eval->4.8177\n",
      "==> Saving model at iter=1000, eval loss->4.8177 \n",
      "Sampling:  Iran; I'll tell her to be as\n",
      "And be not to the world.\n",
      "\n",
      "\n",
      "BETH:\n",
      "The king's a man, that'st it is so,\n",
      "In thy name with a dost to the man.\n",
      "\n",
      "MISO, sir, and this?\n",
      "\n",
      "TOLUS:\n",
      "A:\n",
      "What should see his own good lord.\n",
      "\n",
      "KING HENRY V:\n",
      "DU:\n",
      "O, the man to the king\n",
      "To be\n",
      "...................................................................................................\n",
      "Iter 1100 (0.101 epoch): loss train=4.7358, val=inf, eval->4.7358\n",
      "==> Saving model at iter=1100, eval loss->4.7358 \n",
      "...................................................................................................\n",
      "Iter 1200 (0.110 epoch): loss train=4.6589, val=inf, eval->4.6589\n",
      "==> Saving model at iter=1200, eval loss->4.6589 \n",
      "...................................................................................................\n",
      "Iter 1300 (0.119 epoch): loss train=4.6026, val=inf, eval->4.6026\n",
      "==> Saving model at iter=1300, eval loss->4.6026 \n",
      "...................................................................................................\n",
      "Iter 1400 (0.128 epoch): loss train=4.5415, val=inf, eval->4.5415\n",
      "==> Saving model at iter=1400, eval loss->4.5415 \n",
      "...................................................................................................\n",
      "Iter 1500 (0.138 epoch): loss train=4.4929, val=inf, eval->4.4929\n",
      "==> Saving model at iter=1500, eval loss->4.4929 \n",
      "Sampling:  Neo the matter of his own;\n",
      "I'll be not.\n",
      "\n",
      "SIRANO:\n",
      "But let's the king, to the day.\n",
      "O the prince: I say, I can do not.\n",
      "\n",
      "RUKE V:\n",
      "The very man to the king, but you.\n",
      "\n",
      "PRINUS:\n",
      "The way I did you, and the way of the\n",
      "And you with my father?\n",
      "\n",
      "TIMON:\n",
      "But that, good good lord,\n",
      "...................................................................................................\n",
      "Iter 1600 (0.147 epoch): loss train=4.4525, val=inf, eval->4.4525\n",
      "==> Saving model at iter=1600, eval loss->4.4525 \n",
      "...................................................................................................\n",
      "Iter 1700 (0.156 epoch): loss train=4.4005, val=inf, eval->4.4005\n",
      "==> Saving model at iter=1700, eval loss->4.4005 \n",
      "...................................................................................................\n",
      "Iter 1800 (0.165 epoch): loss train=4.3615, val=inf, eval->4.3615\n",
      "==> Saving model at iter=1800, eval loss->4.3615 \n",
      "...................................................................................................\n",
      "Iter 1900 (0.174 epoch): loss train=4.3174, val=inf, eval->4.3174\n",
      "==> Saving model at iter=1900, eval loss->4.3174 \n",
      "...................................................................................................\n",
      "Iter 2000 (0.183 epoch): loss train=4.2987, val=inf, eval->4.2987\n",
      "==> Saving model at iter=2000, eval loss->4.2987 \n",
      "Sampling: opted with them.\n",
      "\n",
      "DUDELLO:\n",
      "If she was he were a thousand in the king.\n",
      "\n",
      "PRACUSE:\n",
      "I will tell me, for what she's a woman?\n",
      "\n",
      "PRINCESS:\n",
      "I have heard the very great thing.\n",
      "\n",
      "GARBOTTOM:\n",
      "I know no further: you have not\n",
      "I'll do not not, I have the king is: you will\n",
      "he is.\n",
      "\n",
      "FALSTAFF\n",
      "...................................................................................................\n",
      "Iter 2100 (0.193 epoch): loss train=4.2588, val=inf, eval->4.2588\n",
      "==> Saving model at iter=2100, eval loss->4.2588 \n",
      "...................................................................................................\n",
      "Iter 2200 (0.202 epoch): loss train=4.2373, val=inf, eval->4.2373\n",
      "==> Saving model at iter=2200, eval loss->4.2373 \n",
      "...................................................................................................\n",
      "Iter 2300 (0.211 epoch): loss train=4.2060, val=inf, eval->4.2060\n",
      "==> Saving model at iter=2300, eval loss->4.2060 \n",
      "...................................................................................................\n",
      "Iter 2400 (0.220 epoch): loss train=4.1711, val=inf, eval->4.1711\n",
      "==> Saving model at iter=2400, eval loss->4.1711 \n",
      "...................................................................................................\n",
      "Iter 2500 (0.229 epoch): loss train=4.1443, val=inf, eval->4.1443\n",
      "==> Saving model at iter=2500, eval loss->4.1443 \n",
      "Sampling: aunders\n",
      "To our heads to the earth, I'll be.\n",
      "\n",
      "PRIZAN:\n",
      "He was a little most as that I can not not.\n",
      "\n",
      "GLOUCESTER:\n",
      "What, I'll do, sir, I know you.\n",
      "\n",
      "PRINCE RICHARD:\n",
      "O, you are well; and you say you are!\n",
      "\n",
      "SIR TOBY BELCH:\n",
      "What's a man?\n",
      "\n",
      "PRINCE HENRY:\n",
      "O\n",
      "...................................................................................................\n",
      "Iter 2600 (0.238 epoch): loss train=4.1246, val=inf, eval->4.1246\n",
      "==> Saving model at iter=2600, eval loss->4.1246 \n",
      "...................................................................................................\n",
      "Iter 2700 (0.248 epoch): loss train=4.1070, val=inf, eval->4.1070\n",
      "==> Saving model at iter=2700, eval loss->4.1070 \n",
      "...................................................................................................\n",
      "Iter 2800 (0.257 epoch): loss train=4.0957, val=inf, eval->4.0957\n",
      "==> Saving model at iter=2800, eval loss->4.0957 \n",
      "...................................................................................................\n",
      "Iter 2900 (0.266 epoch): loss train=4.0566, val=inf, eval->4.0566\n",
      "==> Saving model at iter=2900, eval loss->4.0566 \n",
      "...................................................................................................\n",
      "Iter 3000 (0.275 epoch): loss train=4.0498, val=inf, eval->4.0498\n",
      "==> Saving model at iter=3000, eval loss->4.0498 \n",
      "Sampling: Cat a fool:\n",
      "If a little is not, he is a fool with you.\n",
      "\n",
      "SIR NATHath, madam:\n",
      "And let him be not, if you be not, but to\n",
      "and I am not: but the matter in this, I\n",
      "not that you should have heard me, and in me a\n",
      "a word.\n",
      "\n",
      "HORATIANO:\n",
      "O, my Lord, I must say.\n",
      "\n",
      "FALSTAFF:\n",
      "Why\n",
      "...................................................................................................\n",
      "Iter 3100 (0.284 epoch): loss train=4.0392, val=inf, eval->4.0392\n",
      "==> Saving model at iter=3100, eval loss->4.0392 \n",
      "...................................................................................................\n",
      "Iter 3200 (0.294 epoch): loss train=4.0169, val=inf, eval->4.0169\n",
      "==> Saving model at iter=3200, eval loss->4.0169 \n",
      "...................................................................................................\n",
      "Iter 3300 (0.303 epoch): loss train=3.9924, val=inf, eval->3.9924\n",
      "==> Saving model at iter=3300, eval loss->3.9924 \n",
      "...................................................................................................\n",
      "Iter 3400 (0.312 epoch): loss train=3.9752, val=inf, eval->3.9752\n",
      "==> Saving model at iter=3400, eval loss->3.9752 \n",
      "...................................................................................................\n",
      "Iter 3500 (0.321 epoch): loss train=3.9725, val=inf, eval->3.9725\n",
      "==> Saving model at iter=3500, eval loss->3.9725 \n",
      "Sampling:  geared of one thing,\n",
      "to the other; the very man's,\n",
      "for no; but by one that she would not be.\n",
      "\n",
      "CELIA:\n",
      "'Tis the doth, sir; you will know him, he must,\n",
      "for she is.\n",
      "\n",
      "Second Clown:\n",
      "He shall find a man; and, he will be well, or\n",
      "and so he is more.\n",
      "\n",
      "Second Servant:\n",
      "What, he has been?\n",
      "\n",
      "HUM\n",
      "...................................................................................................\n",
      "Iter 3600 (0.330 epoch): loss train=3.9438, val=inf, eval->3.9438\n",
      "==> Saving model at iter=3600, eval loss->3.9438 \n",
      "...................................................................................................\n",
      "Iter 3700 (0.339 epoch): loss train=3.9299, val=inf, eval->3.9299\n",
      "==> Saving model at iter=3700, eval loss->3.9299 \n",
      "...................................................................................................\n",
      "Iter 3800 (0.349 epoch): loss train=3.9168, val=inf, eval->3.9168\n",
      "==> Saving model at iter=3800, eval loss->3.9168 \n",
      "...................................................................................................\n",
      "Iter 3900 (0.358 epoch): loss train=3.9039, val=inf, eval->3.9039\n",
      "==> Saving model at iter=3900, eval loss->3.9039 \n",
      "...................................................................................................\n",
      "Iter 4000 (0.367 epoch): loss train=3.8873, val=inf, eval->3.8873\n",
      "==> Saving model at iter=4000, eval loss->3.8873 \n",
      "Sampling:  inn in his eyes,\n",
      "To all the great king of the world and the moon,\n",
      "To see the king of your honour and our eyes\n",
      "And to his brother's, to his grace's,\n",
      "And so much in their eyes of my state's blood!\n",
      "\n",
      "BENEDICK:\n",
      "'I pray you, I have done my mother's death.\n",
      "\n",
      "BASTARD:\n",
      "How now!\n",
      "\n",
      "KING RICHARDINAL WOLINGHAM:\n",
      "And, that\n",
      "...................................................................................................\n",
      "Iter 4100 (0.376 epoch): loss train=3.8695, val=inf, eval->3.8695\n",
      "==> Saving model at iter=4100, eval loss->3.8695 \n",
      "...................................................................................................\n",
      "Iter 4200 (0.385 epoch): loss train=3.8651, val=inf, eval->3.8651\n",
      "==> Saving model at iter=4200, eval loss->3.8651 \n",
      "...................................................................................................\n",
      "Iter 4300 (0.394 epoch): loss train=3.8566, val=inf, eval->3.8566\n",
      "==> Saving model at iter=4300, eval loss->3.8566 \n",
      "...................................................................................................\n",
      "Iter 4400 (0.404 epoch): loss train=3.8448, val=inf, eval->3.8448\n",
      "==> Saving model at iter=4400, eval loss->3.8448 \n",
      "...................................................................................................\n",
      "Iter 4500 (0.413 epoch): loss train=3.8365, val=inf, eval->3.8365\n",
      "==> Saving model at iter=4500, eval loss->3.8365 \n",
      "Sampling:  Researchers of\n",
      "And to be the man of the field of a man,\n",
      "But with the ducats, the Duke of heaven,\n",
      "And his mother to his honour, the world\n",
      "And all a little, of a thousand times\n",
      "That he shall not be in the cause of his hand\n",
      "To make him of the other's bosom.\n",
      "But yet, if this is my lord,\n",
      "I am to make you a good-like life,\n",
      "To hear him what I do love\n",
      "...................................................................................................\n",
      "Iter 4600 (0.422 epoch): loss train=3.8034, val=inf, eval->3.8034\n",
      "==> Saving model at iter=4600, eval loss->3.8034 \n",
      "...................................................................................................\n",
      "Iter 4700 (0.431 epoch): loss train=3.8041, val=inf, eval->3.8041\n",
      "...................................................................................................\n",
      "Iter 4800 (0.440 epoch): loss train=3.7993, val=inf, eval->3.7993\n",
      "==> Saving model at iter=4800, eval loss->3.7993 \n",
      "...................................................................................................\n",
      "Iter 4900 (0.449 epoch): loss train=3.7628, val=inf, eval->3.7628\n",
      "==> Saving model at iter=4900, eval loss->3.7628 \n",
      "...................................................................................................\n",
      "Iter 5000 (0.459 epoch): loss train=3.7665, val=inf, eval->3.7665\n",
      "Sampling:  Crit and the duke's\n",
      "be in his own heart, but to be a little\n",
      "purse of his life's wife; it is a very\n",
      "like in her; and yet, for I must do him.\n",
      "\n",
      "FALSTAFF:\n",
      "Well, he would be a fool; he is in my\n",
      "shill, and not it, as the\n",
      "hath in a jests.\n",
      "\n",
      "FALSTAFF:\n",
      "O, I will be an ass:\n",
      "...................................................................................................\n",
      "Iter 5100 (0.468 epoch): loss train=3.7524, val=inf, eval->3.7524\n",
      "==> Saving model at iter=5100, eval loss->3.7524 \n",
      "...................................................................................................\n",
      "Iter 5200 (0.477 epoch): loss train=3.7500, val=inf, eval->3.7500\n",
      "==> Saving model at iter=5200, eval loss->3.7500 \n",
      "...................................................................................................\n",
      "Iter 5300 (0.486 epoch): loss train=3.7413, val=inf, eval->3.7413\n",
      "==> Saving model at iter=5300, eval loss->3.7413 \n",
      "...................................................................................................\n",
      "Iter 5400 (0.495 epoch): loss train=3.7200, val=inf, eval->3.7200\n",
      "==> Saving model at iter=5400, eval loss->3.7200 \n",
      "...................................................................................................\n",
      "Iter 5500 (0.505 epoch): loss train=3.7225, val=inf, eval->3.7225\n",
      "Sampling: geries of war,\n",
      "But in this great act of his death\n",
      "Of that hath not been with a poor blood;\n",
      "Thy love's tongue is no power: I'll do thee,\n",
      "And to the which thou dost find the world\n",
      "To see the commonwealth of my blood.\n",
      "This is, my lord, that's a king's a queen.\n",
      "\n",
      "JULIA:\n",
      "I am a very true thing.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "If\n",
      "...................................................................................................\n",
      "Iter 5600 (0.514 epoch): loss train=3.7035, val=inf, eval->3.7035\n",
      "==> Saving model at iter=5600, eval loss->3.7035 \n",
      "...................................................................................................\n",
      "Iter 5700 (0.523 epoch): loss train=3.7033, val=inf, eval->3.7033\n",
      "==> Saving model at iter=5700, eval loss->3.7033 \n",
      "...................................................................................................\n",
      "Iter 5800 (0.532 epoch): loss train=3.6795, val=inf, eval->3.6795\n",
      "==> Saving model at iter=5800, eval loss->3.6795 \n",
      "...................................................................................................\n",
      "Iter 5900 (0.541 epoch): loss train=3.6687, val=inf, eval->3.6687\n",
      "==> Saving model at iter=5900, eval loss->3.6687 \n",
      "...................................................................................................\n",
      "Iter 6000 (0.550 epoch): loss train=3.6708, val=inf, eval->3.6708\n",
      "Sampling: iple:\n",
      "What's a gentleman?\n",
      "\n",
      "CALIIA:\n",
      "I have a little way.\n",
      "\n",
      "ROSEN:\n",
      "My lord, you are in love; you will have no\n",
      "greater than your majesty's father. O God,\n",
      "Henceforth be your brother's heart, for the queen\n",
      "That we had have made him as his son, the king\n",
      "Is not noblest, but he's not to know his.\n",
      "\n",
      "HELENA:\n",
      "\n",
      "...................................................................................................\n",
      "Iter 6100 (0.560 epoch): loss train=3.6538, val=inf, eval->3.6538\n",
      "==> Saving model at iter=6100, eval loss->3.6538 \n",
      "...................................................................................................\n",
      "Iter 6200 (0.569 epoch): loss train=3.6512, val=inf, eval->3.6512\n",
      "==> Saving model at iter=6200, eval loss->3.6512 \n",
      "...................................................................................................\n",
      "Iter 6300 (0.578 epoch): loss train=3.6348, val=inf, eval->3.6348\n",
      "==> Saving model at iter=6300, eval loss->3.6348 \n",
      "...................................................................................................\n",
      "Iter 6400 (0.587 epoch): loss train=3.6298, val=inf, eval->3.6298\n",
      "==> Saving model at iter=6400, eval loss->3.6298 \n",
      "...................................................................................................\n",
      "Iter 6500 (0.596 epoch): loss train=3.6179, val=inf, eval->3.6179\n",
      "==> Saving model at iter=6500, eval loss->3.6179 \n",
      "Sampling: Yang thyself for me,\n",
      "If I be as my mother as I do.\n",
      "\n",
      "JULIA:\n",
      "I will not go with her, and give me her leave.\n",
      "\n",
      "JULIA:\n",
      "What's the matter? or do you know that?\n",
      "\n",
      "VIOLA:\n",
      "O, no, no.\n",
      "\n",
      "BIRON:\n",
      "I know not so.\n",
      "\n",
      "PRINCE:\n",
      "No, my good lord; but I have done so.\n",
      "\n",
      "PR\n",
      "...................................................................................................\n",
      "Iter 6600 (0.605 epoch): loss train=3.6178, val=inf, eval->3.6178\n",
      "==> Saving model at iter=6600, eval loss->3.6178 \n",
      "...................................................................................................\n",
      "Iter 6700 (0.615 epoch): loss train=3.6099, val=inf, eval->3.6099\n",
      "==> Saving model at iter=6700, eval loss->3.6099 \n",
      "...................................................................................................\n",
      "Iter 6800 (0.624 epoch): loss train=3.5961, val=inf, eval->3.5961\n",
      "==> Saving model at iter=6800, eval loss->3.5961 \n",
      "...................................................................................................\n",
      "Iter 6900 (0.633 epoch): loss train=3.5987, val=inf, eval->3.5987\n",
      "...................................................................................................\n",
      "Iter 7000 (0.642 epoch): loss train=3.5875, val=inf, eval->3.5875\n",
      "==> Saving model at iter=7000, eval loss->3.5875 \n",
      "Sampling:  largest\n",
      "The winds that they could not do;\n",
      "And then, in their heads be made of all\n",
      "The which they know we had.\n",
      "\n",
      "MORTIMER:\n",
      "What, shall you do me?\n",
      "\n",
      "MISTRESS FORD:\n",
      "A thousand dares.\n",
      "\n",
      "TROILUS:\n",
      "O, sir, do thou tell me what thou canst say?\n",
      "\n",
      "PAGE:\n",
      "Sir, I must not see, or else I am a mad\n",
      "\n",
      "...................................................................................................\n",
      "Iter 7100 (0.651 epoch): loss train=3.5728, val=inf, eval->3.5728\n",
      "==> Saving model at iter=7100, eval loss->3.5728 \n",
      "...................................................................................................\n",
      "Iter 7200 (0.660 epoch): loss train=3.5680, val=inf, eval->3.5680\n",
      "==> Saving model at iter=7200, eval loss->3.5680 \n",
      "...................................................................................................\n",
      "Iter 7300 (0.670 epoch): loss train=3.5632, val=inf, eval->3.5632\n",
      "==> Saving model at iter=7300, eval loss->3.5632 \n",
      "...................................................................................................\n",
      "Iter 7400 (0.679 epoch): loss train=3.5601, val=inf, eval->3.5601\n",
      "==> Saving model at iter=7400, eval loss->3.5601 \n",
      "...................................................................................................\n",
      "Iter 7500 (0.688 epoch): loss train=3.5456, val=inf, eval->3.5456\n",
      "==> Saving model at iter=7500, eval loss->3.5456 \n",
      "Sampling:  Tri, and die,\n",
      "But with the earth I am noblest.\n",
      "\n",
      "PRINCESS:\n",
      "Now, my brother, you shall not know that is;\n",
      "I will not speak more than my life, my mother:\n",
      "What, what's the world, that is here a thing,--\n",
      "\n",
      "MARIA:\n",
      "Ay, sir,--\n",
      "\n",
      "LAVORD POLONIUS:\n",
      "It is too, I am not: yet my lord.\n",
      "\n",
      "DICK\n",
      "...................................................................................................\n",
      "Iter 7600 (0.697 epoch): loss train=3.5269, val=inf, eval->3.5269\n",
      "==> Saving model at iter=7600, eval loss->3.5269 \n",
      "...................................................................................................\n",
      "Iter 7700 (0.706 epoch): loss train=3.5292, val=inf, eval->3.5292\n",
      "...................................................................................................\n",
      "Iter 7800 (0.715 epoch): loss train=3.5210, val=inf, eval->3.5210\n",
      "==> Saving model at iter=7800, eval loss->3.5210 \n",
      "...................................................................................................\n",
      "Iter 7900 (0.725 epoch): loss train=3.5195, val=inf, eval->3.5195\n",
      "==> Saving model at iter=7900, eval loss->3.5195 \n",
      "...................................................................................................\n",
      "Iter 8000 (0.734 epoch): loss train=3.5096, val=inf, eval->3.5096\n",
      "==> Saving model at iter=8000, eval loss->3.5096 \n",
      "Sampling:  Ald for the\n",
      "witted son, that's no woman to the king\n",
      "and what's to be?\n",
      "\n",
      "ROSALINE:\n",
      "What is it so?\n",
      "\n",
      "DON PEDRO:\n",
      "Ay, good my liege.\n",
      "\n",
      "PROTEUS:\n",
      "I do not know the very man.\n",
      "\n",
      "BAPTISTA:\n",
      "My wife, this is my lady, that she shall go\n",
      "me to her, to she's as well as you were. How\n",
      "...................................................................................................\n",
      "Iter 8100 (0.743 epoch): loss train=3.4912, val=inf, eval->3.4912\n",
      "==> Saving model at iter=8100, eval loss->3.4912 \n",
      "...................................................................................................\n",
      "Iter 8200 (0.752 epoch): loss train=3.4916, val=inf, eval->3.4916\n",
      "...................................................................................................\n",
      "Iter 8300 (0.761 epoch): loss train=3.4816, val=inf, eval->3.4816\n",
      "==> Saving model at iter=8300, eval loss->3.4816 \n",
      "...................................................................................................\n",
      "Iter 8400 (0.771 epoch): loss train=3.4784, val=inf, eval->3.4784\n",
      "==> Saving model at iter=8400, eval loss->3.4784 \n",
      "...................................................................................................\n",
      "Iter 8500 (0.780 epoch): loss train=3.4810, val=inf, eval->3.4810\n",
      "Sampling:  mastery for my blood!\n",
      "Thou art a maid of a prince, and not the\n",
      "chicest of a poor wretch, but to make thee good\n",
      "In his own tongue: thou art as a man as he\n",
      "To see him. O Lord, he is so well,\n",
      "And is his daughter; she may be a word with her:\n",
      "He may be said, and he'll not.\n",
      "\n",
      "IAGO:\n",
      "Ay, good night:\n",
      "If not the thing,\n",
      "...................................................................................................\n",
      "Iter 8600 (0.789 epoch): loss train=3.4648, val=inf, eval->3.4648\n",
      "==> Saving model at iter=8600, eval loss->3.4648 \n",
      "...................................................................................................\n",
      "Iter 8700 (0.798 epoch): loss train=3.4736, val=inf, eval->3.4736\n",
      "...................................................................................................\n",
      "Iter 8800 (0.807 epoch): loss train=3.4505, val=inf, eval->3.4505\n",
      "==> Saving model at iter=8800, eval loss->3.4505 \n",
      "...................................................................................................\n",
      "Iter 8900 (0.816 epoch): loss train=3.4445, val=inf, eval->3.4445\n",
      "==> Saving model at iter=8900, eval loss->3.4445 \n",
      "...................................................................................................\n",
      "Iter 9000 (0.826 epoch): loss train=3.4390, val=inf, eval->3.4390\n",
      "==> Saving model at iter=9000, eval loss->3.4390 \n",
      "Sampling:  Almost to you,\n",
      "With some unspotted heart-daughters.\n",
      "You are a very little fool, and so\n",
      "As if you have done me true aught:\n",
      "This day to the world. I would to-day,\n",
      "That's too bold in this, and so much as much\n",
      "To do what you would be done to know.\n",
      "I have not heard: 'tis a good thing that,\n",
      "I mean my daughter's son.'\n",
      "\n",
      "CERIMON:\n",
      "...................................................................................................\n",
      "Iter 9100 (0.835 epoch): loss train=3.4325, val=inf, eval->3.4325\n",
      "==> Saving model at iter=9100, eval loss->3.4325 \n",
      "...................................................................................................\n",
      "Iter 9200 (0.844 epoch): loss train=3.4404, val=inf, eval->3.4404\n",
      "...................................................................................................\n",
      "Iter 9300 (0.853 epoch): loss train=3.4251, val=inf, eval->3.4251\n",
      "==> Saving model at iter=9300, eval loss->3.4251 \n",
      "...................................................................................................\n",
      "Iter 9400 (0.862 epoch): loss train=3.4190, val=inf, eval->3.4190\n",
      "==> Saving model at iter=9400, eval loss->3.4190 \n",
      "...................................................................................................\n",
      "Iter 9500 (0.871 epoch): loss train=3.4136, val=inf, eval->3.4136\n",
      "==> Saving model at iter=9500, eval loss->3.4136 \n",
      "Sampling:  Nights, the no more thou hast thy\n",
      "man, but a fool, a little for his mother's\n",
      "man's.\n",
      "\n",
      "SURREY:\n",
      "What's there, sir?\n",
      "\n",
      "MISTRESS QUICKLY:\n",
      "You say that, my lord.\n",
      "\n",
      "SIR HUGH EVANS:\n",
      "What, will you do this?\n",
      "\n",
      "FALSTAFF:\n",
      "He that is the king's son to his father here.\n",
      "\n",
      "MISTRESS\n",
      "...................................................................................................\n",
      "Iter 9600 (0.881 epoch): loss train=3.4012, val=inf, eval->3.4012\n",
      "==> Saving model at iter=9600, eval loss->3.4012 \n",
      "...................................................................................................\n",
      "Iter 9700 (0.890 epoch): loss train=3.4032, val=inf, eval->3.4032\n",
      "...................................................................................................\n",
      "Iter 9800 (0.899 epoch): loss train=3.3993, val=inf, eval->3.3993\n",
      "==> Saving model at iter=9800, eval loss->3.3993 \n",
      "...................................................................................................\n",
      "Iter 9900 (0.908 epoch): loss train=3.3806, val=inf, eval->3.3806\n",
      "==> Saving model at iter=9900, eval loss->3.3806 \n",
      "..................................................................................................."
     ]
    }
   ],
   "source": [
    "# let's train for a while:\n",
    "ben.train(iter_count=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad5d6b6-5994-4828-ac90-8e46f3d891cc",
   "metadata": {},
   "source": [
    "#***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
