{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c0fbbaf-9565-40a9-b378-9f40175390d7",
   "metadata": {},
   "source": [
    "Learn to add two 2-digit numbers with fixed-size padded at the right blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3ce45a-3722-4f8b-ba0b-32ec4a64805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptbench import Sample, LogFlag, Train, empty_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de1360-3928-4c16-b436-4a2b69d5d337",
   "metadata": {},
   "source": [
    "To create train and validation dataset:\n",
    "python prepare_addition.py ../data/add2.txt 2 --sep=\"\\n\" --split=0.9\n",
    "\n",
    "Creates add2.train.txt and add2.val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de89611-55a3-4aa3-a3ca-a829932bf16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90+0=90\\n90+1=91\\n90+2=92\\n90+3=93\\n90+4=94\\n90+5=95\\n90+6=96\\n90+7=97\\n90+8=98\\n90+9=99\\n90+10=100\\n90+11=101\\n90+12=102\\n90+13=103\\n90+14=104\\n90+15=105\\n90+16=106\\n90+17=107\\n90+18=108\\n90+19=109\\n90+20=110\\n90+21=111\\n90+22=112\\n90+23=113\\n90+24=114\\n90+25=115\\n90+26=116\\n90+27=117\\n90+28=118\\n90+29=119\\n90+30=120\\n90+31=121\\n90+32=122\\n90+33=123\\n90+34=124\\n90+35=125\\n90+36=126\\n90+37=127\\n90+38=128\\n90+39=129\\n90+40=130\\n90+41=131\\n90+42=132\\n90+43=133\\n90+44=134\\n90+45=135\\n90+46=136\\n90+47=137\\n90+48=138\\n90+49=139\\n90+50=140\\n90+51=141\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/add2.val.txt', 'r', newline=None) as f:\n",
    "    val_data = f.read()\n",
    "val_data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e9b4f8-5e0c-4ac6-94eb-75cb182c4e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New random seed 3952773132\n",
      "Loading checkpoint from ./models/add2pad/\n",
      "Checkpoint: iter=1900 (27.022 epoch), loss train=0.4691 val=0.7730 eval->0.7730\n",
      "Dataset train_path: ../data/add2.train.txt, val_path: ../data/add2.val.txt, train_split: None, vocab_size: 13\n",
      "Model params: 0.59M\n"
     ]
    }
   ],
   "source": [
    "do = Train('add2pad', log_mask=LogFlag.ALL)\n",
    "\n",
    "# set datasets\n",
    "do.set_datasets('padlinechar', train_path='../data/add2.train.txt', val_path='../data/add2.val.txt')\n",
    "\n",
    "# set config settings\n",
    "cfg = empty_config()\n",
    "cfg.train.log_period=0\n",
    "cfg.model.set(n_layer=6, n_head=6, n_embd=90, block_size=16)\n",
    "cfg.train.set(sample_period=-5)\n",
    "cfg.trainer.set(batch_size=128)\n",
    "\n",
    "# and init a new model with config\n",
    "if do.can_resume():\n",
    "    do.init_resume(cfg)\n",
    "else:\n",
    "    do.init_new(cfg)\n",
    "# print(do.get_config().dump(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7bce5c-e7ce-47b4-9fa4-90cd76004738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['36', '109', '2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_text='30+6=|92+17=|1+1='\n",
    "ans=[]\n",
    "do.sample(start_text, dest=ans, emit_after='=')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f14bcfb4-7811-42ff-b221-06f4f87df91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_text='1+1='\n",
    "ans=[]\n",
    "do.sample(start_text, dest=ans, emit_after='=')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "164f8c0b-cf38-420e-8855-840aa493e6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x00', '+', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do.val_dataset.get_vocab_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df88d219-1533-4949-89c9-673ad5c5f332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([11,  2,  1,  2, 12, 11,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " tensor([ 2,  1,  2, 12, 11,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do.val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "017e1187-4122-47da-a813-50d722ff0c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Batches per epoch: 70\n",
      "iter 0 (0.000 epoch): loss train=2.2203, val=2.2427, eval->2.2427\n",
      "==> Saving model at iter=0, eval loss->2.2427 \n",
      "751=07+91209+10=2142+8+977915+51319264313433122355++5=28+4145+=7==30852=0+45661779997273423+9\n",
      ".CUDA max memory used: 167.94M\n",
      "...................................................................................................iter 100 (1.422 epoch): loss train=1.0493, val=1.0841, eval->1.0841\n",
      "==> Saving model at iter=100, eval loss->1.0841 \n",
      "....................................................................................................iter 200 (2.844 epoch): loss train=0.8439, val=0.9244, eval->0.9244\n",
      "==> Saving model at iter=200, eval loss->0.9244 \n",
      "....................................................................................................iter 300 (4.267 epoch): loss train=0.7623, val=0.8565, eval->0.8565\n",
      "==> Saving model at iter=300, eval loss->0.8565 \n",
      "....................................................................................................iter 400 (5.689 epoch): loss train=0.7154, val=0.8515, eval->0.8515\n",
      "==> Saving model at iter=400, eval loss->0.8515 \n",
      "....................................................................................................iter 500 (7.111 epoch): loss train=0.6851, val=0.8069, eval->0.8069\n",
      "==> Saving model at iter=500, eval loss->0.8069 \n",
      "38+25=549\n",
      "....................................................................................................iter 600 (8.533 epoch): loss train=0.6672, val=0.8895, eval->0.8895\n",
      "....................................................................................................iter 700 (9.956 epoch): loss train=0.6516, val=0.9496, eval->0.9496\n",
      "....................................................................................................iter 800 (11.378 epoch): loss train=0.6407, val=0.9480, eval->0.9480\n",
      "....................................................................................................iter 900 (12.800 epoch): loss train=0.6322, val=0.8956, eval->0.8956\n",
      "....................................................................................................iter 1000 (14.222 epoch): loss train=0.6120, val=0.9937, eval->0.9937\n",
      "36+14=57\n",
      "....................................................................................................iter 1100 (15.644 epoch): loss train=0.5643, val=0.8448, eval->0.8448\n",
      "....................................................................................................iter 1200 (17.067 epoch): loss train=0.5387, val=0.8135, eval->0.8135\n",
      "....................................................................................................iter 1300 (18.489 epoch): loss train=0.5134, val=0.8261, eval->0.8261\n",
      "....................................................................................................iter 1400 (19.911 epoch): loss train=0.5078, val=0.8642, eval->0.8642\n",
      "....................................................................................................iter 1500 (21.333 epoch): loss train=0.4964, val=0.8711, eval->0.8711\n",
      "1+24=16\n",
      "....................................................................................................iter 1600 (22.756 epoch): loss train=0.4888, val=0.8432, eval->0.8432\n",
      "....................................................................................................iter 1700 (24.178 epoch): loss train=0.4793, val=0.8367, eval->0.8367\n",
      "....................................................................................................iter 1800 (25.600 epoch): loss train=0.4696, val=0.8716, eval->0.8716\n",
      "....................................................................................................iter 1900 (27.022 epoch): loss train=0.4691, val=0.7730, eval->0.7730\n",
      "==> Saving model at iter=1900, eval loss->0.7730 \n",
      "....................................................................................................iter 2000 (28.444 epoch): loss train=0.4603, val=0.8243, eval->0.8243\n",
      "5+18=33\n",
      "....................................................................................................iter 2100 (29.867 epoch): loss train=0.4582, val=0.8590, eval->0.8590\n",
      "....................................................................................................iter 2200 (31.289 epoch): loss train=0.4572, val=0.8617, eval->0.8617\n",
      "....................................................................................................iter 2300 (32.711 epoch): loss train=0.4528, val=0.8029, eval->0.8029\n",
      "....................................................................................................iter 2400 (34.133 epoch): loss train=0.4512, val=0.8875, eval->0.8875\n",
      "....................................................................................................iter 2500 (35.556 epoch): loss train=0.4494, val=0.9674, eval->0.9674\n",
      "80+1=71\n",
      "....................................................................................................iter 2600 (36.978 epoch): loss train=0.4480, val=0.9245, eval->0.9245\n",
      "....................................................................................................iter 2700 (38.400 epoch): loss train=0.4465, val=0.8660, eval->0.8660\n",
      "....................................................................................................iter 2800 (39.822 epoch): loss train=0.4443, val=0.8579, eval->0.8579\n",
      "....................................................................................................iter 2900 (41.244 epoch): loss train=0.4448, val=0.9790, eval->0.9790\n",
      "....................................................................................................iter 3000 (42.667 epoch): loss train=0.4430, val=0.9792, eval->0.9792\n",
      "51+46=97\n",
      "....................................................................................................iter 3100 (44.089 epoch): loss train=0.4412, val=0.9219, eval->0.9219\n",
      "....................................................................................................iter 3200 (45.511 epoch): loss train=0.4414, val=0.9889, eval->0.9889\n",
      "....................................................................................................iter 3300 (46.933 epoch): loss train=0.4411, val=0.9877, eval->0.9877\n",
      "....................................................................................................iter 3400 (48.356 epoch): loss train=0.4404, val=0.9751, eval->0.9751\n",
      "....................................................................................................iter 3500 (49.778 epoch): loss train=0.4389, val=0.9646, eval->0.9646\n",
      "0+28=28\n",
      "....................................................................................................iter 3600 (51.200 epoch): loss train=0.4381, val=0.9482, eval->0.9482\n",
      "....................................................................................................iter 3700 (52.622 epoch): loss train=0.4382, val=1.0209, eval->1.0209\n",
      "....................................................................................................iter 3800 (54.044 epoch): loss train=0.4387, val=0.9872, eval->0.9872\n",
      "....................................................................................................iter 3900 (55.467 epoch): loss train=0.4385, val=0.9592, eval->0.9592\n",
      "....................................................................................................iter 4000 (56.889 epoch): loss train=0.4378, val=0.9149, eval->0.9149\n",
      "+5=74=1\n",
      "....................................................................................................iter 4100 (58.311 epoch): loss train=0.4376, val=0.9627, eval->0.9627\n",
      "....................................................................................................iter 4200 (59.733 epoch): loss train=0.4372, val=0.8009, eval->0.8009\n",
      "....................................................................................................iter 4300 (61.156 epoch): loss train=0.4376, val=0.8902, eval->0.8902\n",
      "....................................................................................................iter 4400 (62.578 epoch): loss train=0.4373, val=1.0061, eval->1.0061\n",
      "....................................................................................................iter 4500 (64.000 epoch): loss train=0.4372, val=0.9612, eval->0.9612\n",
      "9+40=49\n",
      "....................................................................................................iter 4600 (65.422 epoch): loss train=0.4369, val=0.9588, eval->0.9588\n",
      "....................................................................................................iter 4700 (66.844 epoch): loss train=0.4371, val=0.9680, eval->0.9680\n",
      "....................................................................................................iter 4800 (68.267 epoch): loss train=0.4368, val=0.9365, eval->0.9365\n",
      "....................................................................................................iter 4900 (69.689 epoch): loss train=0.4372, val=1.0176, eval->1.0176\n",
      "....................................................................................................iter 5000 (71.111 epoch): loss train=0.4363, val=1.0153, eval->1.0153\n",
      "20+73=93\n",
      "....................................................................................................iter 5100 (72.533 epoch): loss train=0.4361, val=0.9677, eval->0.9677\n",
      "....................................................................................................iter 5200 (73.956 epoch): loss train=0.4363, val=1.0108, eval->1.0108\n",
      "....................................................................................................iter 5300 (75.378 epoch): loss train=0.4366, val=1.0179, eval->1.0179\n",
      "....................................................................................................iter 5400 (76.800 epoch): loss train=0.4363, val=1.0154, eval->1.0154\n",
      "....................................................................................................iter 5500 (78.222 epoch): loss train=0.4361, val=1.0186, eval->1.0186\n",
      "24+38=62\n",
      "....................................................................................................iter 5600 (79.644 epoch): loss train=0.4362, val=1.0122, eval->1.0122\n",
      "....................................................................................................iter 5700 (81.067 epoch): loss train=0.4364, val=0.9910, eval->0.9910\n",
      "....................................................................................................iter 5800 (82.489 epoch): loss train=0.4358, val=1.0251, eval->1.0251\n",
      "....................................................................................................iter 5900 (83.911 epoch): loss train=0.4358, val=1.0443, eval->1.0443\n",
      "....................................................................................................iter 6000 (85.333 epoch): loss train=0.4357, val=0.9745, eval->0.9745\n",
      "47+6=53\n",
      "....................................................................................................iter 6100 (86.756 epoch): loss train=0.4361, val=1.0518, eval->1.0518\n",
      "....................................................................................................iter 6200 (88.178 epoch): loss train=0.4366, val=1.0445, eval->1.0445\n",
      "....................................................................................................iter 6300 (89.600 epoch): loss train=0.4363, val=1.0329, eval->1.0329\n",
      "....................................................................................................iter 6400 (91.022 epoch): loss train=0.4354, val=0.9963, eval->0.9963\n",
      "....................................................................................................iter 6500 (92.444 epoch): loss train=0.4356, val=1.0336, eval->1.0336\n",
      "\u0000+78=86\n",
      "....................................................................................................iter 6600 (93.867 epoch): loss train=0.4361, val=1.0227, eval->1.0227\n",
      "....................................................................................................iter 6700 (95.289 epoch): loss train=0.4362, val=1.0605, eval->1.0605\n",
      "....................................................................................................iter 6800 (96.711 epoch): loss train=0.4358, val=1.0428, eval->1.0428\n",
      "....................................................................................................iter 6900 (98.133 epoch): loss train=0.4360, val=1.0896, eval->1.0896\n",
      "....................................................................................................iter 7000 (99.556 epoch): loss train=0.4353, val=1.0560, eval->1.0560\n",
      "\u000061=121\n",
      "....................................................................................................iter 7100 (100.978 epoch): loss train=0.4350, val=1.0117, eval->1.0117\n",
      "....................................................................................................iter 7200 (102.400 epoch): loss train=0.4356, val=1.0620, eval->1.0620\n",
      "....................................................................................................iter 7300 (103.822 epoch): loss train=0.4357, val=0.9865, eval->0.9865\n",
      "....................................................................................................iter 7400 (105.244 epoch): loss train=0.4355, val=1.0622, eval->1.0622\n",
      "....................................................................................................iter 7500 (106.667 epoch): loss train=0.4351, val=1.0705, eval->1.0705\n",
      "63+27=90\n",
      "....................................................................................................iter 7600 (108.089 epoch): loss train=0.4351, val=0.9993, eval->0.9993\n",
      "....................................................................................................iter 7700 (109.511 epoch): loss train=0.4354, val=1.0525, eval->1.0525\n",
      "....................................................................................................iter 7800 (110.933 epoch): loss train=0.4356, val=1.0379, eval->1.0379\n",
      "....................................................................................................iter 7900 (112.356 epoch): loss train=0.4358, val=0.9788, eval->0.9788\n",
      "....................................................................................................iter 8000 (113.778 epoch): loss train=0.4357, val=1.0763, eval->1.0763\n",
      "64+44=108\n",
      "....................................................................................................iter 8100 (115.200 epoch): loss train=0.4351, val=1.0043, eval->1.0043\n",
      "....................................................................................................iter 8200 (116.622 epoch): loss train=0.4355, val=1.1029, eval->1.1029\n",
      "....................................................................................................iter 8300 (118.044 epoch): loss train=0.4354, val=1.0875, eval->1.0875\n",
      "....................................................................................................iter 8400 (119.467 epoch): loss train=0.4354, val=1.0576, eval->1.0576\n",
      "....................................................................................................iter 8500 (120.889 epoch): loss train=0.4355, val=1.0457, eval->1.0457\n",
      "1+21=22\n",
      "....................................................................................................iter 8600 (122.311 epoch): loss train=0.4353, val=1.1108, eval->1.1108\n",
      "....................................................................................................iter 8700 (123.733 epoch): loss train=0.4355, val=1.0939, eval->1.0939\n",
      "....................................................................................................iter 8800 (125.156 epoch): loss train=0.4357, val=1.1271, eval->1.1271\n",
      "....................................................................................................iter 8900 (126.578 epoch): loss train=0.4355, val=1.1222, eval->1.1222\n",
      "....................................................................................................iter 9000 (128.000 epoch): loss train=0.4351, val=1.0488, eval->1.0488\n",
      "58+85=143\n",
      "....................................................................................................iter 9100 (129.422 epoch): loss train=0.4354, val=1.1052, eval->1.1052\n",
      "....................................................................................................iter 9200 (130.844 epoch): loss train=0.4348, val=1.1052, eval->1.1052\n",
      "....................................................................................................iter 9300 (132.267 epoch): loss train=0.4348, val=1.0990, eval->1.0990\n",
      "....................................................................................................iter 9400 (133.689 epoch): loss train=0.4351, val=1.0606, eval->1.0606\n",
      "....................................................................................................iter 9500 (135.111 epoch): loss train=0.4349, val=1.1307, eval->1.1307\n",
      "+5=5=30\n",
      "....................................................................................................iter 9600 (136.533 epoch): loss train=0.4354, val=1.1006, eval->1.1006\n",
      "....................................................................................................iter 9700 (137.956 epoch): loss train=0.4354, val=1.0318, eval->1.0318\n",
      "....................................................................................................iter 9800 (139.378 epoch): loss train=0.4350, val=1.1260, eval->1.1260\n",
      "....................................................................................................iter 9900 (140.800 epoch): loss train=0.4349, val=1.1178, eval->1.1178\n",
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "do.train(iter_count=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4aaac146-aab3-4a3a-bdee-413fdeb44c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10+20=30\n"
     ]
    }
   ],
   "source": [
    "do.sample(start_text=\"10+20=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6437d8e-f549-4a1c-893a-3929fa15105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n"
     ]
    }
   ],
   "source": [
    "do.sample(start_text=\"94+97=\", emit_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5550267f-266d-4cd4-b07d-9db86903a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(first_number, second_number):\n",
    "    qa = []\n",
    "    for a in range(100):\n",
    "        for b in range(100):\n",
    "            qa.append((f'{a}+{b}=', f'{a+b}'))\n",
    "\n",
    "    qa=qa[first_number*100:second_number*100]\n",
    "    \n",
    "    sep = do.get_config().sample.start_text_sep\n",
    "    start_text = sep.join([q for q,a in qa])\n",
    "\n",
    "    ans = []\n",
    "    do.sample(start_text, dest=ans, emit_after='=')\n",
    "\n",
    "    corr=0\n",
    "    for i in range(len(qa)):\n",
    "        q,a = qa[i]\n",
    "        #print(q,a,ans[i])\n",
    "        if a == ans[i]:\n",
    "            corr+=1\n",
    "        \n",
    "    print(f'{corr/len(qa):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd36529-76cd-4750-b920-5c891eb336c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.422\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(90, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c07c3372-b1cf-4d4f-9022-9e427906bb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2503c088-eacb-4f25-8a02-d4c08389f28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.621\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(10, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc26c8-78e4-41a8-bac5-e8ccebc18529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
