{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c0fbbaf-9565-40a9-b378-9f40175390d7",
   "metadata": {},
   "source": [
    "Learn to add two 2-digit numbers with fixed-size padded at the right blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3ce45a-3722-4f8b-ba0b-32ec4a64805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptbench import Sample, LogFlag, Train, empty_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de1360-3928-4c16-b436-4a2b69d5d337",
   "metadata": {},
   "source": [
    "To create train and validation dataset:\n",
    "python prepare_addition.py ../data/add2.txt 2 --sep=\"\\n\" --split=0.9\n",
    "\n",
    "Creates add2.train.txt and add2.val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de89611-55a3-4aa3-a3ca-a829932bf16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90+0=90\\n90+1=91\\n90+2=92\\n90+3=93\\n90+4=94\\n90+5=95\\n90+6=96\\n90+7=97\\n90+8=98\\n90+9=99\\n90+10=100\\n90+11=101\\n90+12=102\\n90+13=103\\n90+14=104\\n90+15=105\\n90+16=106\\n90+17=107\\n90+18=108\\n90+19=109\\n90+20=110\\n90+21=111\\n90+22=112\\n90+23=113\\n90+24=114\\n90+25=115\\n90+26=116\\n90+27=117\\n90+28=118\\n90+29=119\\n90+30=120\\n90+31=121\\n90+32=122\\n90+33=123\\n90+34=124\\n90+35=125\\n90+36=126\\n90+37=127\\n90+38=128\\n90+39=129\\n90+40=130\\n90+41=131\\n90+42=132\\n90+43=133\\n90+44=134\\n90+45=135\\n90+46=136\\n90+47=137\\n90+48=138\\n90+49=139\\n90+50=140\\n90+51=141\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/add2.val.txt', 'r', newline=None) as f:\n",
    "    val_data = f.read()\n",
    "val_data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e9b4f8-5e0c-4ac6-94eb-75cb182c4e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New random seed 768391787\n",
      "Loading checkpoint from ./models/add2pad/\n",
      "Checkpoint: iter=1900 (27.022 epoch), loss train=0.4691 val=0.7730 eval->0.7730\n",
      "Dataset train_path: ../data/add2.train.txt, val_path: ../data/add2.val.txt, train_split: None, vocab_size: 13\n",
      "Model params: 0.59M\n"
     ]
    }
   ],
   "source": [
    "ben = Train('add2pad', log_mask=LogFlag.ALL)\n",
    "\n",
    "# set datasets\n",
    "ben.set_datasets('padlinechar', train_path='../data/add2.train.txt', val_path='../data/add2.val.txt')\n",
    "\n",
    "# set config settings\n",
    "cfg = empty_config()\n",
    "cfg.train.log_period=0\n",
    "cfg.model.set(n_layer=6, n_head=6, n_embd=90, block_size=16)\n",
    "cfg.sample.set(top=1, max_batch_size=256) # top_k(1) - always pick the best item\n",
    "cfg.train.set(sample_period=-5)\n",
    "cfg.trainer.set(batch_size=128)\n",
    "\n",
    "# and init a new model with config\n",
    "if ben.can_resume():\n",
    "    ben.init_resume(cfg)\n",
    "else:\n",
    "    ben.init_new(cfg)\n",
    "# print(do.get_config().dump(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e9ba82-16e3-4729-b2c1-30ed84cc588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ben.line_dataset_split_qa(ben.val_dataset, 0, 20, sep='=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef4335d-bda5-40ba-b06a-5d0724bfdd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.542"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ben.val_dataset\n",
    "q,a=ds.sample_split(0, len(ds), sep='=', sep_included=-1)\n",
    "\n",
    "def test(q,a,g):\n",
    "    res = float(a == g)\n",
    "    if not res:\n",
    "        print(f\"{q}: {a} != {g}\")\n",
    "    return res\n",
    "    \n",
    "ben.measure_accuracy(q,a, test_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a2d4269-e604-4434-9703-1ba7763504f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272222222222222"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ben.train_dataset\n",
    "q,a=ds.sample_split(0, len(ds), sep='=', sep_included=-1)\n",
    "ben.measure_accuracy(q,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee8f456-b596-4213-859a-8dd98ceab01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=['30+16=', '91+2=', '11+11=']\n",
    "a=['46','93','22']\n",
    "ben.measure_accuracy(q,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7bce5c-e7ce-47b4-9fa4-90cd76004738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['46', '109', '22']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_text='30+16=|92+17=|11+11='\n",
    "ans=[]\n",
    "ben.sample(start_text, dest=ans, emit_start=False)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f14bcfb4-7811-42ff-b221-06f4f87df91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_text='1+1='\n",
    "ans=[]\n",
    "ben.sample(start_text, dest=ans, emit_after='=')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "164f8c0b-cf38-420e-8855-840aa493e6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1900.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben.state['n_samples']/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017e1187-4122-47da-a813-50d722ff0c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Resuming optimizer state\n",
      "Batches per epoch: 70\n",
      ".CUDA max memory used: 170.00M\n",
      "...................................................................................................iter 2000 (28.444 epoch): loss train=0.4626, val=0.8079, eval->0.8079\n",
      "21+4=25\n",
      "....................................................................................................iter 2100 (29.867 epoch): loss train=0.4588, val=0.8446, eval->0.8446\n",
      "....................................................................................................iter 2200 (31.289 epoch): loss train=0.4554, val=0.9151, eval->0.9151\n",
      "....................................................................................................iter 2300 (32.711 epoch): loss train=0.4531, val=0.8183, eval->0.8183\n",
      "....................................................................................................iter 2400 (34.133 epoch): loss train=0.4496, val=0.8165, eval->0.8165\n",
      "....................................................................................................iter 2500 (35.556 epoch): loss train=0.4495, val=0.8657, eval->0.8657\n",
      "\u00002+4=45\n",
      "....................................................................................................iter 2600 (36.978 epoch): loss train=0.4476, val=0.8909, eval->0.8909\n",
      "....................................................................................................iter 2700 (38.400 epoch): loss train=0.4451, val=0.9399, eval->0.9399\n",
      "....................................................................................................iter 2800 (39.822 epoch): loss train=0.4447, val=0.8858, eval->0.8858\n",
      "....................................................................................................iter 2900 (41.244 epoch): loss train=0.4460, val=0.9383, eval->0.9383\n",
      "....................................................................................................iter 3000 (42.667 epoch): loss train=0.4427, val=0.8936, eval->0.8936\n",
      "60+49=109\n",
      "....................................................................................................iter 3100 (44.089 epoch): loss train=0.4410, val=0.8768, eval->0.8768\n",
      "....................................................................................................iter 3200 (45.511 epoch): loss train=0.4414, val=0.9091, eval->0.9091\n",
      "....................................................................................................iter 3300 (46.933 epoch): loss train=0.4399, val=0.9054, eval->0.9054\n",
      "....................................................................................................iter 3400 (48.356 epoch): loss train=0.4408, val=0.9493, eval->0.9493\n",
      "....................................................................................................iter 3500 (49.778 epoch): loss train=0.4395, val=0.9813, eval->0.9813\n",
      "52+54=106\n",
      "....................................................................................................iter 3600 (51.200 epoch): loss train=0.4399, val=0.8039, eval->0.8039\n",
      "....................................................................................................iter 3700 (52.622 epoch): loss train=0.4391, val=0.9533, eval->0.9533\n",
      "....................................................................................................iter 3800 (54.044 epoch): loss train=0.4393, val=0.9474, eval->0.9474\n",
      "....................................................................................................iter 3900 (55.467 epoch): loss train=0.4381, val=0.9075, eval->0.9075\n",
      "....................................................................................................iter 4000 (56.889 epoch): loss train=0.4389, val=0.9327, eval->0.9327\n",
      "87+89=176\n",
      "....................................................................................................iter 4100 (58.311 epoch): loss train=0.4382, val=0.9111, eval->0.9111\n",
      "....................................................................................................iter 4200 (59.733 epoch): loss train=0.4377, val=0.9755, eval->0.9755\n",
      "....................................................................................................iter 4300 (61.156 epoch): loss train=0.4369, val=0.9946, eval->0.9946\n",
      "....................................................................................................iter 4400 (62.578 epoch): loss train=0.4369, val=0.9057, eval->0.9057\n",
      "....................................................................................................iter 4500 (64.000 epoch): loss train=0.4370, val=1.0106, eval->1.0106\n",
      "26+69=95\n",
      "....................................................................................................iter 4600 (65.422 epoch): loss train=0.4373, val=0.9877, eval->0.9877\n",
      "....................................................................................................iter 4700 (66.844 epoch): loss train=0.4371, val=1.0284, eval->1.0284\n",
      "....................................................................................................iter 4800 (68.267 epoch): loss train=0.4363, val=0.9793, eval->0.9793\n",
      "....................................................................................................iter 4900 (69.689 epoch): loss train=0.4369, val=0.7999, eval->0.7999\n",
      "....................................................................................................iter 5000 (71.111 epoch): loss train=0.4368, val=1.0046, eval->1.0046\n",
      "+7=7=34\n",
      "....................................................................................................iter 5100 (72.533 epoch): loss train=0.4370, val=0.8716, eval->0.8716\n",
      "....................................................................................................iter 5200 (73.956 epoch): loss train=0.4363, val=1.0303, eval->1.0303\n",
      "....................................................................................................iter 5300 (75.378 epoch): loss train=0.4368, val=0.9522, eval->0.9522\n",
      "....................................................................................................iter 5400 (76.800 epoch): loss train=0.4362, val=1.0131, eval->1.0131\n",
      "....................................................................................................iter 5500 (78.222 epoch): loss train=0.4371, val=1.0056, eval->1.0056\n",
      "9+85=94\n",
      "....................................................................................................iter 5600 (79.644 epoch): loss train=0.4370, val=1.0191, eval->1.0191\n",
      "....................................................................................................iter 5700 (81.067 epoch): loss train=0.4356, val=0.9880, eval->0.9880\n",
      "....................................................................................................iter 5800 (82.489 epoch): loss train=0.4362, val=1.0261, eval->1.0261\n",
      "....................................................................................................iter 5900 (83.911 epoch): loss train=0.4361, val=1.0391, eval->1.0391\n",
      "....................................................................................................iter 6000 (85.333 epoch): loss train=0.4359, val=1.0161, eval->1.0161\n",
      "0+1=1\n",
      "....................................................................................................iter 6100 (86.756 epoch): loss train=0.4361, val=1.0418, eval->1.0418\n",
      "....................................................................................................iter 6200 (88.178 epoch): loss train=0.4364, val=1.0157, eval->1.0157\n",
      "....................................................................................................iter 6300 (89.600 epoch): loss train=0.4364, val=1.0226, eval->1.0226\n",
      "....................................................................................................iter 6400 (91.022 epoch): loss train=0.4358, val=1.0344, eval->1.0344\n",
      "....................................................................................................iter 6500 (92.444 epoch): loss train=0.4360, val=1.0363, eval->1.0363\n",
      "0+2=2\n",
      "....................................................................................................iter 6600 (93.867 epoch): loss train=0.4357, val=1.0412, eval->1.0412\n",
      "....................................................................................................iter 6700 (95.289 epoch): loss train=0.4358, val=1.0191, eval->1.0191\n",
      "....................................................................................................iter 6800 (96.711 epoch): loss train=0.4356, val=1.0568, eval->1.0568\n",
      "....................................................................................................iter 6900 (98.133 epoch): loss train=0.4357, val=1.0982, eval->1.0982\n",
      "....................................................................................................iter 7000 (99.556 epoch): loss train=0.4354, val=1.0681, eval->1.0681\n",
      "=8+99=127\n",
      "....................................................................................................iter 7100 (100.978 epoch): loss train=0.4351, val=1.0603, eval->1.0603\n",
      "....................................................................................................iter 7200 (102.400 epoch): loss train=0.4356, val=1.0973, eval->1.0973\n",
      "....................................................................................................iter 7300 (103.822 epoch): loss train=0.4353, val=0.9893, eval->0.9893\n",
      "....................................................................................................iter 7400 (105.244 epoch): loss train=0.4355, val=1.0732, eval->1.0732\n",
      "....................................................................................................iter 7500 (106.667 epoch): loss train=0.4355, val=1.0703, eval->1.0703\n",
      "0+7=7\n",
      "....................................................................................................iter 7600 (108.089 epoch): loss train=0.4355, val=1.0395, eval->1.0395\n",
      "....................................................................................................iter 7700 (109.511 epoch): loss train=0.4355, val=1.0358, eval->1.0358\n",
      "....................................................................................................iter 7800 (110.933 epoch): loss train=0.4354, val=1.0804, eval->1.0804\n",
      "....................................................................................................iter 7900 (112.356 epoch): loss train=0.4352, val=1.0666, eval->1.0666\n",
      "....................................................................................................iter 8000 (113.778 epoch): loss train=0.4361, val=1.1186, eval->1.1186\n",
      "78+8=86\n",
      "....................................................................................................iter 8100 (115.200 epoch): loss train=0.4356, val=1.0371, eval->1.0371\n",
      "....................................................................................................iter 8200 (116.622 epoch): loss train=0.4361, val=1.0807, eval->1.0807\n",
      "....................................................................................................iter 8300 (118.044 epoch): loss train=0.4355, val=1.0027, eval->1.0027\n",
      "........................"
     ]
    }
   ],
   "source": [
    "ben.train(iter_count=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4aaac146-aab3-4a3a-bdee-413fdeb44c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10+20=30\n"
     ]
    }
   ],
   "source": [
    "do.sample(start_text=\"10+20=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6437d8e-f549-4a1c-893a-3929fa15105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n"
     ]
    }
   ],
   "source": [
    "do.sample(start_text=\"94+97=\", emit_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5550267f-266d-4cd4-b07d-9db86903a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(first_number, second_number):\n",
    "    qa = []\n",
    "    for a in range(100):\n",
    "        for b in range(100):\n",
    "            qa.append((f'{a}+{b}=', f'{a+b}'))\n",
    "\n",
    "    qa=qa[first_number*100:second_number*100]\n",
    "    \n",
    "    sep = do.get_config().sample.start_text_sep\n",
    "    start_text = sep.join([q for q,a in qa])\n",
    "\n",
    "    ans = []\n",
    "    do.sample(start_text, dest=ans, emit_after='=')\n",
    "\n",
    "    corr=0\n",
    "    for i in range(len(qa)):\n",
    "        q,a = qa[i]\n",
    "        #print(q,a,ans[i])\n",
    "        if a == ans[i]:\n",
    "            corr+=1\n",
    "        \n",
    "    print(f'{corr/len(qa):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd36529-76cd-4750-b920-5c891eb336c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.422\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(90, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c07c3372-b1cf-4d4f-9022-9e427906bb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2503c088-eacb-4f25-8a02-d4c08389f28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.621\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(10, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc26c8-78e4-41a8-bac5-e8ccebc18529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
