{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c0fbbaf-9565-40a9-b378-9f40175390d7",
   "metadata": {},
   "source": [
    "Learn to add two 2-digit numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3ce45a-3722-4f8b-ba0b-32ec4a64805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptbench import Sample, LogFlag, Train, empty_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de1360-3928-4c16-b436-4a2b69d5d337",
   "metadata": {},
   "source": [
    "Create train and validation dataset:\n",
    "python prepare_addition.py ../data/add2.txt 2 --sep=\"\\n\" --split=0.9\n",
    "\n",
    "Creates add2.train.txt and add2.val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de89611-55a3-4aa3-a3ca-a829932bf16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90+0=90\\n90+1=91\\n90+2=92\\n90+3=93\\n90+4=94\\n90+5=95\\n90+6=96\\n90+7=97\\n90+8=98\\n90+9=99\\n90+10=100\\n90+11=101\\n90+12=102\\n90+13=103\\n90+14=104\\n90+15=105\\n90+16=106\\n90+17=107\\n90+18=108\\n90+19=109\\n90+20=110\\n90+21=111\\n90+22=112\\n90+23=113\\n90+24=114\\n90+25=115\\n90+26=116\\n90+27=117\\n90+28=118\\n90+29=119\\n90+30=120\\n90+31=121\\n90+32=122\\n90+33=123\\n90+34=124\\n90+35=125\\n90+36=126\\n90+37=127\\n90+38=128\\n90+39=129\\n90+40=130\\n90+41=131\\n90+42=132\\n90+43=133\\n90+44=134\\n90+45=135\\n90+46=136\\n90+47=137\\n90+48=138\\n90+49=139\\n90+50=140\\n90+51=141\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/add2.val.txt', 'r', newline=None) as f:\n",
    "    val_data = f.read()\n",
    "val_data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e9b4f8-5e0c-4ac6-94eb-75cb182c4e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New random seed 26158912\n",
      "Initializing new model add2\n",
      "Dataset train_path: ../data/add2.train.txt, val_path_or_train_split: ../data/add2.val.txt, vocab_size: 13\n"
     ]
    }
   ],
   "source": [
    "do = Train('add2', log_mask=LogFlag.ALL)\n",
    "\n",
    "# set datasets\n",
    "do.set_datasets('char', train_path='../data/add2.train.txt', val_path='../data/add2.val.txt')\n",
    "\n",
    "# set config settings\n",
    "cfg = empty_config()\n",
    "cfg.train.log_period=-0.5\n",
    "cfg.model.set(n_layer=6, n_head=6, n_embd=90, block_size=16)\n",
    "cfg.trainer.set(batch_size=128)\n",
    "\n",
    "# and init a new model with config\n",
    "do.init_new(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164f8c0b-cf38-420e-8855-840aa493e6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90+0=90\\n90+1=91\\n90+2=92\\n90+3=93\\n90+4=94\\n90+5=95\\n90+6=96\\n90+7=97\\n90+8=98\\n90+9=99\\n90+10=100\\n90+11=101\\n90+12=102\\n90+13=103\\n90+14=104\\n90+15=105\\n90+16=106\\n90+17=107\\n90+18=108\\n90+19=109\\n90+20=110\\n90+21=111\\n90+22=112\\n90+23=113\\n90+24=114\\n90+25=115\\n90+26=116\\n90+27=117\\n90+28=118\\n90+29=119\\n90+30=120\\n90+31=121\\n90+32=122\\n90+33=123\\n90+34=124\\n90+35=125\\n90+36=126\\n90+37=127\\n90+38=128\\n90+39=129\\n90+40=130\\n90+41=131\\n90+42=132\\n90+43=133\\n90+44=134\\n90+45=135\\n90+46=136\\n90+47=137\\n90+48=138\\n90+49=139\\n90+50=140\\n90+51=141\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do.val_dataset.get_src_data()[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4fa754-2f6a-4806-9ab8-ace3d2bcd6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches per epoch: 648\n",
      "iter 0 | loss 2.5819 | iter_dt 0.00ms\n",
      "..................................................iter 50 | loss 2.1346 | iter_dt 26.99ms\n",
      "..................................................iter 100 | loss 1.9964 | iter_dt 27.98ms\n",
      "iter 100 (0.154 epoch) | eval loss 2.0247 (train=1.9678, val=2.0247)\n",
      "==> Saving model at loss=2.0247 iter=100\n",
      "CUDA max memory used: 169.67M\n",
      "..................................................iter 150 | loss 1.8681 | iter_dt 27.98ms\n",
      ".................................................."
     ]
    }
   ],
   "source": [
    "do.train(iter_count=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aaac146-aab3-4a3a-bdee-413fdeb44c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56+45=12509+1=1529\n",
      "11+788903=89\n",
      "607+6405=110\n",
      "025+187\n",
      "85+12=112\n",
      "38+122=9\n",
      "429\n",
      "8+278=43\n",
      "15+317=9150\n",
      "848+96=18\n"
     ]
    }
   ],
   "source": [
    "do.sample(start_text=\"56+45=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cc1c5db-6312-4848-8f7a-9afff9dc3367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17"
     ]
    }
   ],
   "source": [
    "do.set_sample_config(start_after='=', stop_before='\\n')\n",
    "do.sample(start_text=\"56+45=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496b1e2-f132-4634-aa2a-8cb6d7483590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches per epoch: 648\n",
      "iter 200 | loss 1.7805 | iter_dt 26.98ms\n",
      "iter 200 (0.308 epoch) | eval loss 1.8026 (train=1.7188, val=1.8026)\n",
      "==> Saving model at loss=1.8026 iter=200\n",
      "CUDA max memory used: 169.67M\n",
      "..................................................iter 250 | loss 1.7036 | iter_dt 26.97ms\n",
      "..................................................iter 300 | loss 1.6784 | iter_dt 27.99ms\n",
      "iter 300 (0.462 epoch) | eval loss 1.6917 (train=1.6113, val=1.6917)\n",
      "==> Saving model at loss=1.6917 iter=300\n",
      "..................................................iter 350 | loss 1.6588 | iter_dt 28.99ms\n",
      "..................................................iter 400 | loss 1.5913 | iter_dt 30.97ms\n",
      "iter 400 (0.617 epoch) | eval loss 1.6358 (train=1.5432, val=1.6358)\n",
      "==> Saving model at loss=1.6358 iter=400\n",
      "..................................................iter 450 | loss 1.5447 | iter_dt 29.04ms\n",
      "..................................................iter 500 | loss 1.5180 | iter_dt 29.98ms\n",
      "iter 500 (0.771 epoch) | eval loss 1.5857 (train=1.4684, val=1.5857)\n",
      "==> Saving model at loss=1.5857 iter=500\n",
      "..................................................iter 550 | loss 1.4869 | iter_dt 28.98ms\n",
      "..................................................iter 600 | loss 1.4613 | iter_dt 25.98ms\n",
      "iter 600 (0.925 epoch) | eval loss 1.5436 (train=1.3895, val=1.5436)\n",
      "==> Saving model at loss=1.5436 iter=600\n",
      "..................................................iter 650 | loss 1.4372 | iter_dt 25.98ms\n",
      "..................................................iter 700 | loss 1.3810 | iter_dt 28.98ms\n",
      "iter 700 (1.079 epoch) | eval loss 1.4765 (train=1.2695, val=1.4765)\n",
      "==> Saving model at loss=1.4765 iter=700\n",
      "..................................................iter 750 | loss 1.3041 | iter_dt 28.80ms\n",
      "..................................................iter 800 | loss 1.2318 | iter_dt 27.98ms\n",
      "iter 800 (1.233 epoch) | eval loss 1.3810 (train=1.1320, val=1.3810)\n",
      "==> Saving model at loss=1.3810 iter=800\n",
      "..................................................iter 850 | loss 1.1805 | iter_dt 26.98ms\n",
      "..................................................iter 900 | loss 1.1428 | iter_dt 24.98ms\n",
      "iter 900 (1.387 epoch) | eval loss 1.3180 (train=1.0399, val=1.3180)\n",
      "==> Saving model at loss=1.3180 iter=900\n",
      "..................................................iter 950 | loss 1.0913 | iter_dt 29.40ms\n",
      "..................................................iter 1000 | loss 1.0751 | iter_dt 31.98ms\n",
      "iter 1000 (1.542 epoch) | eval loss 1.2591 (train=0.9840, val=1.2591)\n",
      "==> Saving model at loss=1.2591 iter=1000\n",
      "118..................................................iter 1050 | loss 1.0203 | iter_dt 26.00ms\n",
      "..................................................iter 1100 | loss 1.0290 | iter_dt 26.10ms\n"
     ]
    }
   ],
   "source": [
    "do.train(iter_count=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541276f5-837a-40f2-83d9-0f8f4cf15403",
   "metadata": {},
   "outputs": [],
   "source": [
    "do.train(iter_count=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
