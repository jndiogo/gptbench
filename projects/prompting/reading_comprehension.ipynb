{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94132259-86dc-464d-9ffc-15b9b688d271",
   "metadata": {},
   "source": [
    "By prompting (without previous specific training), how does GPT-2 answer questions about documents?\n",
    "\n",
    "In this notebook we'll follow comprehension experiment mentioned in the [GPT-2 paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf), that uses documents from the [Conversation Question Answering dataset (CoQA)](https://stanfordnlp.github.io/coqa/).\n",
    "\n",
    "Besides testing reading comprehension, this also tests the ability of models to answer questions that depend on conversation history.\n",
    "\n",
    "Following the GPT-2 paper, we'll doing:\n",
    "\n",
    "```\n",
    "Greedy decoding from GPT-2 when conditioned on a document, the history of the associated conversation, and a final token A:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa25cc07-fb63-4b06-bb21-e1f4d755a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from gptbench import Sample, empty_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27a922e-e4de-4464-b36d-97b64dfa6baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model from gpt2-xl\n",
      "Dataset: dummy 0 tokens\n",
      "Dataset: loading uint16 tokens\n",
      "Expanding initial dataset size of 1 (less than block_size+1) by 1025 times to size of 1025\n",
      "Dataset train_path: dummy empty dataset, val_path: None, train_split: 0.9, vocab_size: 50257\n",
      "Model params: 1557.61M\n"
     ]
    }
   ],
   "source": [
    "ben = Sample(seed=0xFACEC0DE)\n",
    "\n",
    "cfg = empty_config()\n",
    "\n",
    "cfg.model.set(dtype='bfloat16')\n",
    "\n",
    "# the next sample config settings are important:\n",
    "# top=1 will only emit the most probable token on each step (greedy argmax) - we want accuracy, not randomness\n",
    "# emit_start=False will skip emitting the initial context\n",
    "cfg.sample.set(top=1, emit_start=False)\n",
    "\n",
    "# if you get an out of memory error, try 'gpt2', the smaller model:\n",
    "ben.init_pretrained('gpt2-xl', cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0fae8d2-b085-41d1-b644-2e9657cb1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use as the answer only the first paragraph\n",
    "def first_paragraph(text, count=1):\n",
    "    s = text.split('.')\n",
    "    return '.'.join(s[:count]) + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d378698e-af61-49bb-9307-f9939c07dfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt is 351 tokens (up to 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' She was a white kitten with orange stripes.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "doc=\"\"\"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. But Cotton wasn't alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton's mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer's orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \n",
    "\n",
    "\"What are you doing, Cotton?!\" \n",
    "\n",
    "\"I only wanted to be more like you\". \n",
    "\n",
    "Cotton's mommy rubbed her face on Cotton's and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton's mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton's fur was all all dry. \n",
    "\n",
    "\"Don't ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn't want that!\" \n",
    "\n",
    "Then Cotton thought, \"I change my mind. I like being special\".\"\"\"\n",
    "\n",
    "start_text = doc + '\\n\\nQ: What color was Cotton?' + '\\nA:'\n",
    "\n",
    "print(f\"Prompt is {len(ben.train_dataset.encode(start_text))} tokens (up to {ben.model.block_size})\")\n",
    "\n",
    "# we're sampling with the sample config settings defined above: top=1, emit_start=False\n",
    "out=[]\n",
    "ben.sample(start_text, dest=out)\n",
    "answer = first_paragraph(out[0]) \n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431f0dbb-184d-4a0b-8f38-d9b1a598a0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' She lived in a barn near a farm house.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the answer to the prompt\n",
    "start_text += answer\n",
    "\n",
    "# next question\n",
    "start_text += '\\nQ: Where did she live?' + '\\nA:'\n",
    "\n",
    "out=[]\n",
    "ben.sample(start_text, dest=out)\n",
    "answer = first_paragraph(out[0]) \n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb63cc22-1bab-4ad7-8099-2eab8c5ad4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' No, she lived with her mommy and 5 other sisters.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add last answer to the prompt\n",
    "start_text += answer\n",
    "\n",
    "# place next question\n",
    "start_text += '\\nQ: Did she live alone?' + '\\nA:'\n",
    "\n",
    "out=[]\n",
    "ben.sample(start_text, dest=out)\n",
    "answer = first_paragraph(out[0]) \n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dddb373e-1253-4a96-83db-19185e616cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Her mommy and 5 other sisters.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add last answer to the prompt\n",
    "start_text += answer\n",
    "\n",
    "# place next question\n",
    "start_text += '\\nQ: Who did she live with?' + '\\nA:'\n",
    "\n",
    "out=[]\n",
    "ben.sample(start_text, dest=out)\n",
    "answer = first_paragraph(out[0]) \n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e31a41-0cea-4aac-9af6-a1a422a69694",
   "metadata": {},
   "source": [
    "Quite good!\n",
    "\n",
    "As noted in the GPT-2 paper:\n",
    "```\n",
    "While GPT-2â€™s performance is exciting for a system without any supervised training, some inspection of its answers and errors suggests GPT-2 often uses simple retrieval based heuristics such as answer with a name from the document in response to a who question.\n",
    "```\n",
    "\n",
    "Still, it's fascinating that asking for 'who' may fetch names. Not smart, but pointing into that direction.\n",
    "\n",
    "Just to recap, the prompt is by now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3e898c1-af74-44b8-92a9-83b134ce792d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. But Cotton wasn't alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton's mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer's orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \n",
      "\n",
      "\"What are you doing, Cotton?!\" \n",
      "\n",
      "\"I only wanted to be more like you\". \n",
      "\n",
      "Cotton's mommy rubbed her face on Cotton's and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton's mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton's fur was all all dry. \n",
      "\n",
      "\"Don't ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn't want that!\" \n",
      "\n",
      "Then Cotton thought, \"I change my mind. I like being special\".\n",
      "\n",
      "Q: What color was Cotton?\n",
      "A: She was a white kitten with orange stripes.\n",
      "Q: Where did she live?\n",
      "A: She lived in a barn near a farm house.\n",
      "Q: Did she live alone?\n",
      "A: No, she lived with her mommy and 5 other sisters.\n",
      "Q: Who did she live with?\n",
      "A: Her mommy and 5 other sisters.\n"
     ]
    }
   ],
   "source": [
    "print(start_text + answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
