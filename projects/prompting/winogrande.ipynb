{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94132259-86dc-464d-9ffc-15b9b688d271",
   "metadata": {},
   "source": [
    "[Winogrand](https://leaderboard.allenai.org/winogrande/submissions/get-started) is a test to measure a model's common sense reasoning capabilities. It's a series of prompts like this one:\n",
    "\n",
    "\"She remembered how annoying it is to dust her wood chair so she bought a plastic table instead.  Cleaning the _ is time consuming.\"\n",
    "\n",
    "Where two options are given to substitude the _ in the text:\n",
    "\n",
    "- 1: \"chair\" <- correct\n",
    "- 2: \"table\"\n",
    "\n",
    "The [GPT-2 paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf) uses a similar dataset (Winograd) for measuring performance, and they do it by looking into the token probabilities of the phrase in the two alternatives, picking the higher one. (See the ../misc/next_token_probs notebook).\n",
    "\n",
    "Let's investigate how this could be done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa25cc07-fb63-4b06-bb21-e1f4d755a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, copy\n",
    "from gptbench import Sample, empty_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27a922e-e4de-4464-b36d-97b64dfa6baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model from gpt2-xl\n",
      "Dataset: dummy 0 tokens\n",
      "Dataset: loading uint16 tokens\n",
      "Expanding initial dataset size of 1 (less than block_size+1) by 1025 times to size of 1025\n",
      "Dataset train_path: dummy empty dataset, val_path: None, train_split: 0.9, vocab_size: 50257\n",
      "Model params: 1557.61M\n"
     ]
    }
   ],
   "source": [
    "ben = Sample(seed=0xDECADEF00D)\n",
    "\n",
    "cfg = empty_config()\n",
    "cfg.model.set(dtype='bfloat16') # halve the memory requirements\n",
    "\n",
    "ben.init_pretrained('gpt2-xl', cfg) # 'gpt2' or 'gpt-xl' if your GPU can handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d378698e-af61-49bb-9307-f9939c07dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's ingest the extra-small test set \n",
    "\n",
    "with open('../data/winogrande/train_xs.jsonl', 'r', encoding='utf-8') as f:\n",
    "    json_lines = list(f)\n",
    "\n",
    "    entries = []\n",
    "\n",
    "for json_str in json_lines:\n",
    "    entry = json.loads(json_str)\n",
    "    \"\"\" Each entry is in the form:\n",
    "{\"qID\": \"3D5G8J4N5CI2K40F4RZLF9OG2CKVTH-2\", \n",
    "\"sentence\": \"Kyle doesn't wear leg warmers to bed, while Logan almost always does. _ is more likely to live in a colder climate.\", \n",
    "\"option1\": \"Kyle\", \"option2\": \"Logan\", \"answer\": \"2\"}\n",
    "    \"\"\"\n",
    "    entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ad9241-27de-4550-b3dd-83447b8ac607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'qID': '3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-2',\n",
       "  'sentence': \"Ian volunteered to eat Dennis's menudo after already having a bowl because _ despised eating intestine.\",\n",
       "  'option1': 'Ian',\n",
       "  'option2': 'Dennis',\n",
       "  'answer': '2'},\n",
       " {'qID': '3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-1',\n",
       "  'sentence': \"Ian volunteered to eat Dennis's menudo after already having a bowl because _ enjoyed eating intestine.\",\n",
       "  'option1': 'Ian',\n",
       "  'option2': 'Dennis',\n",
       "  'answer': '1'},\n",
       " {'qID': '3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-1',\n",
       "  'sentence': 'He never comes to my home, but I always go to his house because the _ is smaller.',\n",
       "  'option1': 'home',\n",
       "  'option2': 'house',\n",
       "  'answer': '1'},\n",
       " {'qID': '3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-2',\n",
       "  'sentence': 'He never comes to my home, but I always go to his house because the _ is bigger.',\n",
       "  'option1': 'home',\n",
       "  'option2': 'house',\n",
       "  'answer': '2'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40db5dc8-e173-4da9-b975-db3e94b6075c",
   "metadata": {},
   "source": [
    "Let's build a helper function to test the options and return their token's probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cddeeda9-0fcf-4375-9be4-7f48b5974615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_probs(start_text_tokens, tokens):\n",
    "    \"\"\"\n",
    "    Returns a list with the probabilities of each token in tokens. After a token is generated, it's added to start_text for the next round\n",
    "    \"\"\"\n",
    "    text_tokens = start_text_tokens[:] # copy as we'll be expanding it with the option tokens\n",
    "    out = []\n",
    "\n",
    "    for t in tokens:\n",
    "        print(tokens, text_tokens, '-->', ben.train_dataset.decode(text_tokens), '/', t, ben.train_dataset.decode(t))\n",
    "        probs = ben.model_probs(text_tokens=text_tokens)\n",
    "        p_t = probs[t].item()\n",
    "        out.append(p_t)\n",
    "        text_tokens.append(t)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43a9b4-2184-4154-ba5f-f951c05fa922",
   "metadata": {},
   "source": [
    "Our first try will just use the probability of the option token used to replace _ in the sentence. It won't use the text following the _ character. To keep thinks simple for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b156fc5-69ef-4556-8b0d-2ebeb475b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_next1(sentence, op1, op2, answer, prob_calc):\n",
    "    \"\"\"\n",
    "    Decide by comparing probabilities of generating the two options, when generating right before the _ character in the sentence\n",
    "    We'll prepend a space to the options and remove the space before _ in the sentence if any.\n",
    "    When an option is encoded to several tokens, we'll use the mean of probabilities.\n",
    "    Returns True if it found the correct answer.\n",
    "    \"\"\"\n",
    "\n",
    "    index = sentence.index(' _')\n",
    "    if index < 0:\n",
    "        index = sentence.index('_')\n",
    "    sent = sentence[:index]\n",
    "    sent_tok = ben.train_dataset.encode(sent)\n",
    "    \n",
    "    op1_tok = ben.train_dataset.encode(' ' + op1)\n",
    "    op2_tok = ben.train_dataset.encode(' ' + op2)\n",
    "    print(op1_tok, op2_tok)\n",
    "\n",
    "    p_op1 = calc_probs(sent_tok, op1_tok)\n",
    "    p_op2 = calc_probs(sent_tok, op2_tok)\n",
    "\n",
    "    print(p_op1, p_op2)\n",
    "\n",
    "    # calc probabilities\n",
    "    if prob_calc == 'mean':\n",
    "        p_op1 = sum(p_op1) / len(p_op1)\n",
    "        p_op2 = sum(p_op2) / len(p_op2)\n",
    "        \n",
    "    elif prob_calc == 'mult':\n",
    "        p1 = 1.\n",
    "        for p in p_op1:\n",
    "            p1*=p\n",
    "        p_op1=p1\n",
    "        p2 = 1.\n",
    "        for p in p_op2:\n",
    "            p2*=p\n",
    "        p_op2=p2\n",
    "    else:\n",
    "        assert False, \"Unknown prob_calc\"\n",
    "\n",
    "    print(p_op1, p_op2)\n",
    "   \n",
    "    if answer == 1:\n",
    "        return p_op1 > p_op2\n",
    "    else:\n",
    "        return p_op2 > p_op1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c650e132-234a-4ed2-a449-3fc4616bdeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4171] [7872, 12, 79, 676]\n",
      "[4171] [464, 6766, 318] --> The sky is / 4171  blue\n",
      "[7872, 12, 79, 676] [464, 6766, 318] --> The sky is / 7872  yellow\n",
      "[7872, 12, 79, 676] [464, 6766, 318, 7872] --> The sky is yellow / 12 -\n",
      "[7872, 12, 79, 676] [464, 6766, 318, 7872, 12] --> The sky is yellow- / 79 p\n",
      "[7872, 12, 79, 676] [464, 6766, 318, 7872, 12, 79] --> The sky is yellow-p / 676 ink\n",
      "[0.09228515625] [0.00066375732421875, 0.003448486328125, 0.00115966796875, 0.96484375]\n",
      "0.09228515625 0.24252891540527344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_next1('The sky is _ and etc.', 'blue', 'yellow-pink', 1, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "835b3865-9581-4bdc-b1a2-30589cad85d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4171] [7872, 680]\n",
      "[4171] [464, 6766, 318] --> The sky is / 4171  blue\n",
      "[7872, 680] [464, 6766, 318] --> The sky is / 7872  yellow\n",
      "[7872, 680] [464, 6766, 318, 7872] --> The sky is yellow / 680 ish\n",
      "[0.09228515625] [0.00066375732421875, 0.0028533935546875]\n",
      "0.09228515625 1.8939608708024025e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_next1('The sky is _ and etc.', 'blue', 'yellowish', 1, 'mult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9484d4ad-3e8f-4317-9ea7-696339ae8f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5118] [3084]\n",
      "[5118] [3347, 12086, 703, 15774, 340, 318, 284, 8977, 607, 4898, 5118, 523, 673, 5839, 257, 7309, 3084, 2427, 13, 5985, 278, 262] --> She remembered how annoying it is to dust her wood chair so she bought a plastic table instead. Cleaning the / 5118  chair\n",
      "[3084] [3347, 12086, 703, 15774, 340, 318, 284, 8977, 607, 4898, 5118, 523, 673, 5839, 257, 7309, 3084, 2427, 13, 5985, 278, 262] --> She remembered how annoying it is to dust her wood chair so she bought a plastic table instead. Cleaning the / 3084  table\n",
      "[0.04150390625] [0.326171875]\n",
      "0.04150390625 0.326171875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_next1(\"She remembered how annoying it is to dust her wood chair so she bought a plastic table instead. Cleaning the _ is time consuming.\",\n",
    "             \"chair\", \"table\", 1, 'mult')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35365a6d-9731-4c10-b246-4c51eea726f8",
   "metadata": {},
   "source": [
    "The choose_next1() method of just looking into the probabilities of the options doesn't look very reliable. Let's look into other ways.\n",
    "\n",
    "To be continued..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
